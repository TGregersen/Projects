# from github ugik notebooks Simple_Neural_Network.ipynb
# from chatbotslife.com/how_neural_networks_work-ff4c7ad17f

import numpy as np

class NeuralNetwork():
	def __init__(self):

		# Seed random for same number each run
		np.random.seed(1)

		# Model single neuron, 3 inputs 1 output, 
		#   random weights to a 3x1 matrix, values -1 to 1
		self.synaptic_weights = 2 * np.random.random((4, 1)) - 1

	# Sigmoid fn, describes an S shaped curve. 
	#   pass weighted sums to normalize between 0 n 1.
	def __sigmoid(self, x):
		return 1/(1+np.exp(-x))

	# Sigmoid deriv, gradient of curve, indicates confid of existing weight.
	def __sigmoid_derivative(self, x):
		return x * (1 - x)

	# Train through trial and error, adjust weights each time.
	def train(self, training_set_inputs, training_set_outputs, 
		number_of_training_iterations):
		for iteration in iter(range(number_of_training_iterations)):
			
			# Pass training through network (single neuron).
			output = self.think(training_set_inputs)

			# Calculate % error, different between desired and predicted.
			error = training_set_outputs - output

			# Mltply the err by input and again by gradient of SIGCURV, less 
			#   confident adjust more, input 0 do not change weights.
			# Dot product gives the prediction
			adjustment = np.dot(training_set_inputs.T, 
				error * self.__sigmoid_derivative(output))

			# Adjust weights
			self.synaptic_weights += adjustment
			if (iteration % 1000 == 0):
				print ("error after %s iterations: %s" % (iteration, 
					str(np.mean(np.abs(error)))))
						#!^^ OFF BY 1 DISPLAY ERROR, NUMPY INSTEAD OF NP

	# Network Thinks
	def think(self, inputs):

		# Pass inputs through network.
		return self.__sigmoid(np.dot(inputs, self.synaptic_weights))

if __name__ == "__main__":

	# Init a single neuron neural network.
	neural_network = NeuralNetwork()

	print ("Random starting synaptic weights: ")
	print (neural_network.synaptic_weights)

	# Training set, 3 inputs, 1 output, each.
	training_set_inputs = np.array([[0, 0, 1, 0], [1 ,1 ,0 ,1], [1, 0, 0, 1], 
		[0, 1, 1, 0]]) #MISSING BRACKET SET
	training_set_outputs = np.array([[0, 1, 1, 0]]).T

	# Train the network. do it 20000 times and make adjustments.
	neural_network.train(training_set_inputs, training_set_outputs, 1000000)

	print("New synaptic weights after training: ")
	print(neural_network.synaptic_weights)

	# Test the neural network with a new pattern
	test = [1, 0, 0, 1]
	print ("Considering new situation %s -> ?: " % test)
	print (neural_network.think(np.array(test)))